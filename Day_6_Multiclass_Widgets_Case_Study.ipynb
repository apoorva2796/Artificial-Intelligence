{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv layers\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(64, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Conv2D(64,(3,3),input_shape = (150,150,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected layers\n",
    "model.add(Flatten())  \n",
    " \n",
    "model.add(Dense( activation = 'relu', units=64))\n",
    "\n",
    "model.add(Dense( activation = 'relu', units=64))\n",
    "\n",
    "model.add(Dense( activation = 'relu', units=64))\n",
    "\n",
    "model.add(Dense( activation = 'softmax', units=11)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "       )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7040 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        r'D:/Shweta_workspace/Term-3/AI/dataset/casestudy-Widgets/UI-Widget-case study/training_set',\n",
    "        target_size=(150, 150),\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        r'D:/Shweta_workspace/Term-3/AI/dataset/casestudy-Widgets/UI-Widget-case study/test_set',\n",
    "        target_size=(150, 150),\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "220/220 [==============================] - 422s 2s/step - loss: 0.1936 - acc: 0.9449 - val_loss: 0.0287 - val_acc: 0.9946\n",
      "Epoch 2/5\n",
      "220/220 [==============================] - 410s 2s/step - loss: 0.0178 - acc: 0.9949 - val_loss: 0.0076 - val_acc: 0.9982\n",
      "Epoch 3/5\n",
      "220/220 [==============================] - 462s 2s/step - loss: 0.0191 - acc: 0.9957 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "220/220 [==============================] - 641s 3s/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.0161 - val_acc: 0.9929\n",
      "Epoch 5/5\n",
      "220/220 [==============================] - 662s 3s/step - loss: 0.0612 - acc: 0.9903 - val_loss: 0.0311 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2293c971550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_set,\n",
    "        epochs=5,\n",
    "        validation_data=test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cards': 0,\n",
       " 'checkbox': 1,\n",
       " 'combobox': 2,\n",
       " 'enable_disable': 3,\n",
       " 'forward': 4,\n",
       " 'home': 5,\n",
       " 'information_icon': 6,\n",
       " 'tabview': 7,\n",
       " 'textbox': 8,\n",
       " 'window_header': 9,\n",
       " 'zoom': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction of single new data\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image= image.load_img(r'D:/Shweta_workspace/Term-3/AI/dataset/casestudy-Widgets/UI-Widget-case study/fwd1.png'\n",
    "                           ,target_size =(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAIAAACzY+a1AAADJUlEQVR4nO3dMU4iURyAcVlslYTCxAJK4xUI3ILKE3AkPYKFtzAh3sDYGSoSQgGhhi1eMmR9ywjDMPC9+X7Vi7LJuF/eH2Zw8OpKknSUxmazOfcxqIhGoxEWf857HDqeCfGus1W2MXXJ4ic+dyGeCfFMiGdCPBPimRDPhHgmxDMhngnxTIhnQjwT4pkQz4R4JsQzIZ4J8UyIZ0I8E+KZEM+EeCbEMyGeCfFMiGdCPBPimRDPhHgmxLv+/SEX7O3tLSyGw2FY1PBGV3chngnxth9aQhxBOZ+4Qvxx9hH3chfimRCP/Yo0npbZnEE/QRzEXYhnQjz2II1lYzOeqHd3d2Exm82qP7DTcRfimRCPfWq/j/j0fzqdhsX9/X3lh3MsT+0TZEK89AdpJo0Lqg7SBJkQL7VT+xzxWX8m/gpotLoL8UyIV6NBmsl5iyrnK09PT2Hx+vp6ogMrxl2IZ0K8Gp3aH+Tz8zMsHh8fdz3mLP9jntonyIR4DtJ9fX19hcXDw8OPb63X67BoNpunPgwHaYJMiOcgLe4s7145SBNkQrw6XiM90vPz86+P2eePXJc1bN2FeCbEKzhIJ5NJWHQ6nfIOphZKf7HqLsQzIV7BQdrtdsNin5deaB8fH2HR6/X2/1eLxSIsbm9vw+L7+7vU49pyF+KZEM9rpGWq4Kqp10gTZEI8r5EWNxqNwuLl5WXXYyp4enIX4pkQz0F6sEu71dRdiGdCPAfpL3LG5ng8Dot+v1/V4fyHuxDPhHgO0n9U+WtLZXEX4pkQr9aDtN1uh8V8Pt/1mEsbmzF3IZ4J8eo4SLM7OuMh2Wq1wmK5XFZ6TEdwF+KZEK9Gg/TS3iQqi7sQz4R46Q/SVOdnxl2IZ0K81AbpYDAIi/f39x/fWq1WYXFzc1PpMZ2YuxDPhHjsQZp9WGj28aGxNF525nAX4pkQj32LaPKn7TFvEU2QCfHYr0hTnZYHcRfimRDPhHgmxDMhngnxTIhnQjwT4pkQz4R4JsQzIZ4J8UyIZ0I8E+KZEM+EeCbEMyGeCfFMiGdCPBPimRBv+wv5yf890FS5C/FMKEmqu7/fCbP+yqlpLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x150 at 0x2293DB5DA20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert image to array\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "test_image=test_image.reshape(1,150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single prediction change the dimension using axis. To remove problem of batch\n",
    "#test_image = np.expand_dims(test_image,axis = 0)\n",
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=result.argmax()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cards': 0, 'checkbox': 1, 'combobox': 2, 'enable_disable': 3, 'forward': 4, 'home': 5, 'information_icon': 6, 'tabview': 7, 'textbox': 8, 'window_header': 9, 'zoom': 10}\n"
     ]
    }
   ],
   "source": [
    "label_map = (train_set.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class label \n",
    "\n",
    "if result == 0:\n",
    "    prediction = 'cards'\n",
    "elif result == 1:\n",
    "    prediction = 'checkbox'\n",
    "elif result == 2:\n",
    "    prediction = 'combobox'\n",
    "elif result == 3:\n",
    "    prediction = 'enable_disable'\n",
    "elif result == 4:\n",
    "    prediction = 'forward'\n",
    "elif result == 5:\n",
    "    prediction = 'home'\n",
    "elif result == 6:\n",
    "    prediction = 'information_icon'\n",
    "elif result == 7:\n",
    "    prediction = 'tabview'\n",
    "elif result == 8:\n",
    "    prediction = 'textbox'\n",
    "elif result == 9:\n",
    "    prediction = 'window_header'\n",
    "else:\n",
    "    prediction = 'bike'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
